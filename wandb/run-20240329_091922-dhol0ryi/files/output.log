
Model size: 10716353 parameters
Epoch:  0  | Train loss:  1.4957423210144043 | Validation loss:  1.6226747035980225 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  10  | Train loss:  1.5116337537765503 | Validation loss:  1.622855305671692 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  20  | Train loss:  1.4836463928222656 | Validation loss:  1.6159828901290894 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  30  | Train loss:  1.506748080253601 | Validation loss:  1.6199103593826294 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  40  | Train loss:  1.4847508668899536 | Validation loss:  1.6202421188354492 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  50  | Train loss:  1.4737343788146973 | Validation loss:  1.6337730884552002 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  60  | Train loss:  1.4567079544067383 | Validation loss:  1.614992380142212 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  70  | Train loss:  1.4697191715240479 | Validation loss:  1.6028422117233276 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  80  | Train loss:  1.464343786239624 | Validation loss:  1.6050931215286255 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  90  | Train loss:  1.5051058530807495 | Validation loss:  1.609919548034668 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  100  | Train loss:  1.4995955228805542 | Validation loss:  1.6241463422775269 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  110  | Train loss:  1.4785890579223633 | Validation loss:  1.6068238019943237 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  120  | Train loss:  1.4839602708816528 | Validation loss:  1.6162337064743042 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  130  | Train loss:  1.4848195314407349 | Validation loss:  1.6232091188430786 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  140  | Train loss:  1.5145158767700195 | Validation loss:  1.603408694267273 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  150  | Train loss:  1.4860104322433472 | Validation loss:  1.604070782661438 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  160  | Train loss:  1.4630990028381348 | Validation loss:  1.60535728931427 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  170  | Train loss:  1.4984550476074219 | Validation loss:  1.6244611740112305 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  180  | Train loss:  1.484019160270691 | Validation loss:  1.6198999881744385 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  190  | Train loss:  1.476682424545288 | Validation loss:  1.6106302738189697 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  200  | Train loss:  1.513708233833313 | Validation loss:  1.6016645431518555 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  210  | Train loss:  1.4411190748214722 | Validation loss:  1.597396969795227 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  220  | Train loss:  1.4459792375564575 | Validation loss:  1.6056861877441406 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  230  | Train loss:  1.4951262474060059 | Validation loss:  1.6106959581375122 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  240  | Train loss:  1.468320369720459 | Validation loss:  1.6032543182373047 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  250  | Train loss:  1.4464855194091797 | Validation loss:  1.6068401336669922 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  260  | Train loss:  1.4840478897094727 | Validation loss:  1.6105393171310425 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  270  | Train loss:  1.4393912553787231 | Validation loss:  1.602884292602539 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Epoch:  280  | Train loss:  1.4511793851852417 | Validation loss:  1.5972613096237183 | lr: 0.0001
Training checkpoint saved at ./models/checkpoints/shakespeare_char
Traceback (most recent call last):
  File "/Users/shwetank/code/wiki-base/train.py", line 191, in <module>
    main(args.total_epochs, args.save_every, args.warmup_epochs, batch_size)
  File "/Users/shwetank/code/wiki-base/train.py", line 171, in main
    trainer.train(total_epochs)
  File "/Users/shwetank/code/wiki-base/train.py", line 154, in train
    self._run_epoch(epoch)
  File "/Users/shwetank/code/wiki-base/train.py", line 119, in _run_epoch
    tr_lossi, val_lossi = self._evaluate_loss({'train': (xtr, ytr), 'validation': (xval, yval)}, num_batches=eval_batch_size)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shwetank/code/wiki-base/makemore11/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shwetank/code/wiki-base/train.py", line 91, in _evaluate_loss
    _, train_loss = self.model(xtr, ytr)
                    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/shwetank/code/wiki-base/makemore11/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shwetank/code/wiki-base/makemore11/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shwetank/code/wiki-base/models/wiki2.py", line 86, in forward
    x = self.blocks(x)
        ^^^^^^^^^^^^^^
  File "/Users/shwetank/code/wiki-base/makemore11/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shwetank/code/wiki-base/makemore11/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shwetank/code/wiki-base/makemore11/lib/python3.11/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/Users/shwetank/code/wiki-base/makemore11/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shwetank/code/wiki-base/makemore11/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shwetank/code/wiki-base/models/wiki2.py", line 66, in forward
    sa_out = self.sa_head(self.ln1(x))
                          ^^^^^^^^^^^
  File "/Users/shwetank/code/wiki-base/makemore11/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shwetank/code/wiki-base/makemore11/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shwetank/code/wiki-base/makemore11/lib/python3.11/site-packages/torch/nn/modules/normalization.py", line 201, in forward
    return F.layer_norm(
           ^^^^^^^^^^^^^
  File "/Users/shwetank/code/wiki-base/makemore11/lib/python3.11/site-packages/torch/nn/functional.py", line 2546, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt